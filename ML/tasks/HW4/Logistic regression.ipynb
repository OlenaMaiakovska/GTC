{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from model import Model\n",
    "\n",
    "class Config(object):\n",
    "  \"\"\"Holds model hyperparams and data information.\n",
    "\n",
    "  The config class is used to store various hyperparameters and dataset\n",
    "  information parameters. Model objects are passed a Config() object at\n",
    "  instantiation.\n",
    "  \"\"\"\n",
    "  batch_size = 64\n",
    "  n_samples = 1024\n",
    "  n_features = 100\n",
    "  n_classes = 2\n",
    "  max_epochs = 50\n",
    "  lr = 1e-4 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(Model):\n",
    "  \"\"\"Implements a LR classifier with cross-entropy loss.\"\"\"\n",
    "\n",
    "  def load_data(self):\n",
    "    \"\"\"Creates a synthetic dataset and stores it in memory.\"\"\"\n",
    "    self.input_data = np.genfromtxt('./data/train.csv', delimiter=',')\n",
    "    self.input_labels = \n",
    "\n",
    "  def add_placeholders(self):\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    ### END YOUR CODE\n",
    "\n",
    "  def create_feed_dict(self, input_batch, label_batch):\n",
    "    \"\"\"Creates the feed_dict for softmax classifier.\n",
    "\n",
    "    A feed_dict takes the form of:\n",
    "\n",
    "    feed_dict = {\n",
    "        <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "        ....\n",
    "    }\n",
    "\n",
    "    If label_batch is None, then no labels are added to feed_dict.\n",
    "\n",
    "    Hint: The keys for the feed_dict should match the placeholder tensors\n",
    "          created in add_placeholders.\n",
    "    \n",
    "    Args:\n",
    "      input_batch: A batch of input data.\n",
    "      label_batch: A batch of label data.\n",
    "    Returns:\n",
    "      feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    ### END YOUR CODE\n",
    "    return feed_dict\n",
    "\n",
    "  def add_training_op(self, loss):\n",
    "    \"\"\"Sets up the training Ops.\n",
    "\n",
    "    Creates an optimizer and applies the gradients to all trainable variables.\n",
    "    The Op returned by this function is what must be passed to the\n",
    "    `sess.run()` call to cause the model to train. See \n",
    "\n",
    "    https://www.tensorflow.org/versions/r0.7/api_docs/python/train.html#Optimizer\n",
    "\n",
    "    for more information.\n",
    "\n",
    "    Hint: Use tf.train.GradientDescentOptimizer to get an optimizer object.\n",
    "          Calling optimizer.minimize() will return a train_op object.\n",
    "\n",
    "    Args:\n",
    "      loss: Loss tensor, from cross_entropy_loss.\n",
    "    Returns:\n",
    "      train_op: The Op for training.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    ### END YOUR CODE\n",
    "    return train_op\n",
    "\n",
    "  def add_model(self, input_data):\n",
    "    \"\"\"Adds a linear-layer plus a softmax transformation\n",
    "\n",
    "    The core transformation for this model which transforms a batch of input\n",
    "    data into a batch of predictions. In this case, the mathematical\n",
    "    transformation effected is\n",
    "\n",
    "    y = softmax(xW + b)\n",
    "\n",
    "    Hint: Make sure to create tf.Variables as needed. Also, make sure to use\n",
    "          tf.name_scope to ensure that your name spaces are clean.\n",
    "    Hint: For this simple use-case, it's sufficient to initialize both weights W\n",
    "          and biases b with zeros.\n",
    "\n",
    "    Args:\n",
    "      input_data: A tensor of shape (batch_size, n_features).\n",
    "    Returns:\n",
    "      out: A tensor of shape (batch_size, n_classes)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    ### END YOUR CODE\n",
    "    return out\n",
    "\n",
    "  def add_loss_op(self, pred):\n",
    "    \"\"\"Adds cross_entropy_loss ops to the computational graph.\n",
    "\n",
    "    Hint: Use the cross_entropy_loss function we defined. This should be a very\n",
    "          short function.\n",
    "    Args:\n",
    "      pred: A tensor of shape (batch_size, n_classes)\n",
    "    Returns:\n",
    "      loss: A 0-d tensor (scalar)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    raise NotImplementedError\n",
    "    ### END YOUR CODE\n",
    "    return loss\n",
    "\n",
    "  def run_epoch(self, sess, input_data, input_labels):\n",
    "    \"\"\"Runs an epoch of training.\n",
    "\n",
    "    Trains the model for one-epoch.\n",
    "  \n",
    "    Args:\n",
    "      sess: tf.Session() object\n",
    "      input_data: np.ndarray of shape (n_samples, n_features)\n",
    "      input_labels: np.ndarray of shape (n_samples, n_classes)\n",
    "    Returns:\n",
    "      average_loss: scalar. Average minibatch loss of model on epoch.\n",
    "    \"\"\"\n",
    "    # And then after everything is built, start the training loop.\n",
    "    average_loss = 0\n",
    "    for step, (input_batch, label_batch) in enumerate(\n",
    "        data_iterator(input_data, input_labels,\n",
    "                      batch_size=self.config.batch_size,\n",
    "                      label_size=self.config.n_classes)):\n",
    "\n",
    "      # Fill a feed dictionary with the actual set of images and labels\n",
    "      # for this particular training step.\n",
    "      feed_dict = self.create_feed_dict(input_batch, label_batch)\n",
    "\n",
    "      # Run one step of the model.  The return values are the activations\n",
    "      # from the `self.train_op` (which is discarded) and the `loss` Op.  To\n",
    "      # inspect the values of your Ops or variables, you may include them\n",
    "      # in the list passed to sess.run() and the value tensors will be\n",
    "      # returned in the tuple from the call.\n",
    "      _, loss_value = sess.run([self.train_op, self.loss], feed_dict=feed_dict)\n",
    "      average_loss += loss_value\n",
    "\n",
    "    average_loss = average_loss / step\n",
    "    return average_loss \n",
    "\n",
    "  def fit(self, sess, input_data, input_labels):\n",
    "    \"\"\"Fit model on provided data.\n",
    "\n",
    "    Args:\n",
    "      sess: tf.Session()\n",
    "      input_data: np.ndarray of shape (n_samples, n_features)\n",
    "      input_labels: np.ndarray of shape (n_samples, n_classes)\n",
    "    Returns:\n",
    "      losses: list of loss per epoch\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for epoch in range(self.config.max_epochs):\n",
    "      start_time = time.time()\n",
    "      average_loss = self.run_epoch(sess, input_data, input_labels)\n",
    "      duration = time.time() - start_time\n",
    "      # Print status to stdout.\n",
    "      print('Epoch %d: loss = %.2f (%.3f sec)'\n",
    "             % (epoch, average_loss, duration))\n",
    "      losses.append(average_loss)\n",
    "    return losses\n",
    "\n",
    "  def __init__(self, config):\n",
    "    \"\"\"Initializes the model.\n",
    "\n",
    "    Args:\n",
    "      config: A model configuration object of type Config\n",
    "    \"\"\"\n",
    "    self.config = config\n",
    "    # Generate placeholders for the images and labels.\n",
    "    self.load_data()\n",
    "    self.add_placeholders()\n",
    "    self.pred = self.add_model(self.input_placeholder)\n",
    "    self.loss = self.add_loss_op(self.pred)\n",
    "    self.train_op = self.add_training_op(self.loss)\n",
    "  \n",
    "def test_SoftmaxModel():\n",
    "  \"\"\"Train softmax model for a number of steps.\"\"\"\n",
    "  config = Config()\n",
    "  with tf.Graph().as_default():\n",
    "    model = SoftmaxModel(config)\n",
    "  \n",
    "    # Create a session for running Ops on the Graph.\n",
    "    sess = tf.Session()\n",
    "  \n",
    "    # Run the Op to initialize the variables.\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "  \n",
    "    losses = model.fit(sess, model.input_data, model.input_labels)\n",
    "\n",
    "  # If ops are implemented correctly, the average loss should fall close to zero\n",
    "  # rapidly.\n",
    "  assert losses[-1] < .5\n",
    "  print \"Basic (non-exhaustive) classifier tests pass\\n\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_SoftmaxModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
